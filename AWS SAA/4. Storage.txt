EBS Volumes
-------------
What's an EBS Volume?

An EBS (Elastic Block Store) Volume is a network drive you can attach to your
instances while they run.
It allows your instances to persist data, even after their termination
They are bound to a specific availability zone
Free tier: 30 GB of free EBS storage of type General Purpose (SSD) or Magnetic per month

Its a network drive (i.e. not a physical drive)
    It uses the network to communicate the instance, which means there might be a bit of latency.
    It can be detached from an EC2 instance and attached to another one quickly

Its locked to an Availability Zone (AZ)
    An EBS Volume in us-east-1 a cannot be attached to us-east-1b
    To move a volume across, you first need to snapshot It

Have a provisioned capacity (size in GBs, and IOPS)
    You get billed for all the provisioned capacity
    You can increase the capacity of the drive over time

EBS - Delete on Termination attribute

Controls the EBS behaviour when an EC2 instance terminates
    By default, the root EBS volume is deleted (attribute enabled)
    By default, any other attached EBS volume is not deleted (attribute disabled)
This can be controlled by the AWS console/AWS CLI
Use case: preserve root volume when instance is terminated

EBS Volumes Types
------------------
EBS Volumes come in 6 Types
    gp2 / gp3 (SSD): General purpose SSD volume that balances price and performance for a wide variety of workloads
    io1 / io2 (SSD): Highest-performance SSD volume for mission-critical low-latency or high-throughput workloads
    st1 (HDD): Low cost HDD volume designed for frequently accessed, throughput-intensive workloads
    sc 1 (HDD): Lowest cost HDD volume designed for less frequently accessed workloads

EBS Volumes are characterized in Size | Throughput | IOPS (I/O Ops Per Sec)
Only gp2/gp3 and io1/io2 can be used as boot volumes

    EBS Volumes Types Use cases 
    ----------------------------
        General Purpose SSD
            Cost effective storage, low latency
            System boot volumes, Virtual desktops, Development and test environments
            1 GiB - 16 TiB
            gp3:
                Baseline of 3000 IOPS and throughput of 125 MiB/s
                Can increase IOPS up to 16000 and throughput up to 1000 MiB/s independently
            gp2:
                Small gp2 volumes can burst IOPS to 3000
                Size of the volume and IOPS are linked, max IOPS is 16000
                3 IOPS per GB, means at 5334 GB we are at the max IOPS
        
        Provisioned IOPS (PIOPS) SSD
            Critical Business applications with sustained IOPS performance
            Or applications that need more than 16000 IOPS
            Great for databases workloads (sensitive to storage perf and consistency)
            io1/io2 (4 GiB - 16 TiB):
                Max PIOPS: 64000 for Nitro EC2 instances and 32000 for other
                Can increase PIOPS independently from storage size
                io2 have more durability and more IOPS per GiB (at the same price as io1)
            io2 Block Express (4 GiB - 64 TiB):
                Sub-millisecond latency
                Max PIOPS: 256000 with an IOPS:GiB ratio of 1000:1
            Supports EBS Multi-attach

        Hard Disk Drives (HDD)
            Cannot be a boot volume
            125 MiB to 16 TiB
            Throughput Optimized HDD (st1)
                Big Data, Data Warehouses, Long Processing
                Max throughput 500 MiB/s - max IOPS 500
            Cold HDD (sc1):
                For data is infrequently accessed
                Scenarios where lowest cost is important
                Max throughput 250 MiB/s - max IOPS 250
    
    EBS Multi-Attach - io1/io2 family
    -----------------------------------
    Attach the same EBS volume to multiple EC2 instances in th same AZ
    Each instance has full read and write permissions to the high-performance volume
    Use case:
        Achieve higher application availability in clustered Linux applications (ex: Teradata)
        Applications must manage concurrent write operations 
    Upto 16 EC2 Instances at a time
    Must use a file system thats's cluster-aware (not XFS, EX4, etc...)


EBS Encryption
---------------
When you create an encrypted EBS volume, you get the foloowing:
    Data at rest is encrypted inside the volume
    All the data in flight moving between the instances and the volume is encrypted
    All snapshots are encrypted
    All volumes created from the snapshot
Encryption and decryption are handled transparently (you have nothing to do)
Encryption has a minimal impact on latency
EBS Encryption leverages keys from KMS (AES-256)
Copying an unencrypted snapshot allows encryption
Snapshots of encrypted volumes are encrypted

How to encrypt an unencrypted EBS volume
    Create an EBS snapshot of the volume
    Encrypt the EBS snapshot ( using copy )
    Create new ebs volume from the snapshot ( the volume will also be encrypted )
    Now you can attach the encrypted volume to the original instance

Creata a snapshot > Go to shanpshot page > actions > copy snapshot > enable encryption > copy snapshot > 
select copied snapshot > actions > create volume from snapshot > Create Volume

EBS Snapshots
--------------
Make a backup (snapshot) of your EBS volume at a point in time
Not necessary to detach volume to do snapshot, but recommended
Can copy snapshots across AZ or Region

    EBS Snapshot Features

        EBS Snapshot Archive
            Move a Snapshot to an "archive tier" that is 75% cheaper
            Takes within 24 to 72 hours for restoring the archive
        
        Recycle Bin for EBS Snapshots
            Setup rules to retain deleted snapshots so you can recover them after an accidental deletion
            Specify retention (from 1 day to 1 year)

        Fast Snapshot Restore (FSR)
            Force full initialization of snapshot to have no latency on the first use
 
Hands-On:
    Select Snapshot > Actions > Create snapshot 
    Elastic Block Store(Menu) > Snapshots > select > rightclickCopy > select destination region > Copy snapshot

    Select Snapshot > Actions > Create volume from snapshot > select AZ > Create Volume

    Using Recycle Bin we can recover snapshots



AMI
------
AMI = Amazon Machine Image
AMI are a customization of the EC2 instance
    You add your own software, configuration, operating system, monitoring ...
    Faster boot/configuration time because all your software is pre-packed
AMI are built for a specific region (and can be copied across regions)
You can launch EC2 instances from:
    A Public AMI: AWS provided
    Your own AMI: you make and maintain them yourself
    An AWS Marketplace AMI: an AMI someone else made (and potentially sells)

    AMI Process (from an EC2 instance)
        Start an EC2 instance and customize it
        Stop the instance (for data integrity)
        Build an AMI - this will also create EBS snapshots
        Launch instances from other AMIs

    Hands-On:
        Create a EC2 Instnace and Customize it > Rightclick 
        > Image and template > Create image > Enter details > Create Image


EC2 Instance Store
--------------------
EBS volumes are network drives with good but 'limited' performance
If you need a high-performance hardware disk, use EC2 Instance Store
Better I/O performance
EC2 Instnace Store lose their storage if they're stopped 
Good for buffer / cache / scratch data / temporary content
Risk of data loss if hardware fails
Backups and Replication are your responsibility


Amazon - EFS (Elastic File System)
----------------------------------- 
Managed NFS (network file system) that can be mounted on many EC2
EFS works with EC2 instances in multi-AZ
Highly available, scalable, expensive (3x gp2), pay per use

Use-Cases:
    content management, web serving, data sharing, Wordpress
    Uses NFSv4.1 protocol
    Uses security group to control access to EFS
    Compatible with Linux based AMI (not Windows)
    Encryption at rest using KMS
    POSIX file system (~Linux) that has a standard file API
    File system scales automatically, pay-per-use, no capacity planning

EFS Scale:
    1000s of concurrent NFS clients, 10GB + /s throughput
    Grow to Petabyte-scale network file system, automatically

Performance mode (set at EFS creation time)
    General purpose (default): latency-sensitive use case (web server, CMS, etc...)
    Max I/O - higher latency, throughput, highly parallel (big data, media Processing)

Throughput mode
    Bursting (1TB=50MiB/s + bursty of upto 100MiB/s)
    Provisioned: set your throughput regardless of storage size, ex:1GiB/s or 1 TB storage

EFS - Storage Class
    Storage Tiers (lifecycle management feature - move file after N days)
        Sta ndard: for frequently accessed files
        Infrequent access (EFS-IA): cost to retrieve files, lower price to Store, Enable EFS-IA with a Lifecycle Policy
    Availability and durability
        Standard: Multi-AZ, great for prod 
        One Zone: One AZ, great for dev, backup enabled by default, compatible with IA (EFS One Zone-IA)
    Over 90% in cost savings

EBS vs EFS 
------------
EBS Volumes 
        can be attached to only one instance at a time 
        are locked at the Availability Zone level
        gp2LIO increases if the disk size increases
        io1: can increase IO independently
    To migrate an EBS volume across AZ
        Take a snapshot
        Restore the snapshot to another AZ
        EBS backups use IO and you shouldn't run them while your application is handling a lot of traffic
    Root EBS Volumes of instances get terminated by default if the EC2 instance get terminated

EFS Volumes 
    Mounting 100s of instances across AZ
    EFS share website files (WordPress)
    Only for Linux Instances (POSIX)
    EFS has a higher price point than EBS
    Can leverage EFS-IA for cost savings






Amazon FSx - Overview
----------------------
Launch 3rd party high-performance file systems on AWS
Fully managed service
	- FSx for Lusture
	- FSx for Windows File Server
	- FSx for NetApp ONTAP
	- FSx for OpenZFS

Amazon FSx for Windows (File Server)
	FSx for Windows is a fully managed Windows file system share drive
	Supports SMB protocol & Windows NTFS
	Microsoft Active Directory integration, ACLs, user quotas
	Can be mounted on Linux EC2 instances
	Supports Microsoft's Distributed File System (DFS) Namespaces (group files across multiple FS)

	Scale up to 10s of GB/s, millions of IOPS, 100s PB of data
	Storage Options:
		SSD - latency sensitive workloads (databases, media processing, data analytics)
		HDD - broad spectrum of workloads (home directory, CMS, ...)
	Can be accessed from your on-premises infrastructure (VPN or Direct Connect)
	Can be configured to be Multi-AZ (high availability)
	Data is backed-up daily to S3

Amazon FSx for Lusture 
	Lusture is a type of parallel distributed file system, for large-scale computing
	The name Lusture is derived from "Linux" and "cluster"
	Machine Learning, High Performance Computing (HPC)
	Video Processing, Financial Modeling, Electronic Design Automation
	Scales upto 100s of GB/, millions of IOPS, sub-ms latency
	Storage Options:
		SSD - low latency, IOPS intensive workloads, small and random file operations
		HDD - throughput-intensive workloads, large & sequential file operations
	Seamless integration with S3
		Can "read S3" as a file system (through FSx)
		Can write the output of the computations back to S3 (through FSx)
	Can be used from on-premises servers (VPN or Direct Connect)

	FSx File system Deployment Options
		Scratch File System
			Temporary Storage
			Data is not replicated (doesn't persist if the file server fails)
			High burst (6x faster, 200MBps per TB)
			Usage: short-term processing, optimize costs
		Persistent File System
			Long-term storage
			Data is replicated with same AZ
			Replace failed files within minutes
			Usage: Long-term processing, sensitive data
Amazon FSx for NetApp ONTAP
	Managed NetApp ONTAP on AWS
	File System compatible with NFS, SMB, iSCSI protocol
	Move workloads running on ONTAP or NAS to AWS
	Works with:
		Linux
		Windows
		MacOS
		VMware Cloud on AWS 
		Amazon Workspaces & AppStream 2.0
		Amazon EC2, ECS and EKS 
	Storage shrinks or grows automatically
	Snapshots, replication, low-cost, compression and data de-duplication
	Point-in-time instantaneous cloning (helpful for testing new workloads)

Amazon FSx for OpenZFS
	Managed OpenZFS file system on AWS
	File System compatible with NFS (v3, v4, v4.1, v4.2)
	Move workloads running on ZFS to AWS
	Works with:
		Linux
		Windows
		MacOS
		VMware Cloud on AWS
		Amazon Workspaces & AppStream 2.0
		Amazon EC2, ECS and EKS
	Up to 1000000 IOPS with <0.5ms latency
	Snapshots, compression and low-cost
	Point-in-time instantaneous cloning (helpful for testing new workloads)


Storage Gateway
-------------------
Hybrid Cloud for Storage
	AWS is pushing for "hybrid cloud"
		Part of your infrastructure is on the cloud
		Part of your infrastructure is on-premises
	This can be due to
		Long cloud migrations
		Security requirements
		Compliance requirements
		IT strategy
	S3 is a proprietary storage technology (unlike EFS / NFS), so how do you expose the S3 data on-premises
	The Bridge between S3 and on-premises is going to be AWS Storage Gateway
	
	AWS Storage Gateway
		Bridge between on-premises data and cloud data
		Use-cases:
			data recovery
			backup & restore
			tiered storage
			on-premises cache & low-latency files access
		Types of Storage Gateway:
			S3 File Gateway
			FSx File Gateway
			Volume Gateway
			Tape Gateway

S3 File Gateway
	We want to connect S3 bucket to an on premises application server but we want to use a standard network file system. 
	So we create an S3 file gateway which is going to allow our application server to use the NFS or SMB protocol and by using this protocol
	behind the scenes the S3 file gateway is going to translate those request into https request for AWS S3 bucket 

	Configured S3 buckets are accessible using the NFS and SMB protocol
	Most recently used data is cached in the file gateway
	Supports S3 Standard, S3 Standard IA, S3 One Zone A, S3 Intelligent Tiering
	Transition to S3 Glacier using a Lifecycle Policy
	Bucket access using IAM roles for each File Gateway
	SMB Protocol has integration with Active Directory (AD) for user authentication 

FSx File Gateway
	Native access to Amazon FSx for Windows File Server
	Local cache for frequently accessed data
	Windows native compatibaility (SMB, NTFS, Active Directory...)
	Useful for group file shares and home directories 

Volume Gateway
	Block storage using iSCSI protocal backed by S3
	Backed by EBS snapshots which can help restore on-premises volumes!
	Cached volumes: low latency access to most recent data
	Stored volumes: entire dataset is on premise, scheduled backups to S3
	
Tape Gateway
	Some companies have backup processes using physical tapes
	With Tape Gateway, companies us the same processes but, in the cloud
	Virtual Tape Library (VTL) backed by Amazon S3 and Glacier
	Backup data using existing tape-based processes (and iSCSI interface)
	Works with lending backup software vendors

Storage Gateway - Hardware appliance
	Using Storage Gateway means you need on-premises virtualization
	Othewise you can use a Storage Gateway Hardware Appliance
	You can buy it on amazon.com
	Works with File Gateway, Volume Gateway, Tape Gateway
	Has the required CPU, memory, network, SSD cache resources
	Helpful for daily NFS backups in samll data centers

AWS Storage Gateway
	Bridge between on-premises data and cloud data
	Use cases:
	    - disaster recovery
	    - backup & restore
	    - tiered storage
	    - on-premises cache & low-latency file access


AWS Transfer Family - Overview
------------------------------------
A fully managed service for file transfers into and out of Amazon S3 or Amazon EFS using the FTP protocol
Supported Protocols
	AWS Transfer for FTP (File Transfer Protocol(FTP))
	AWS Transfer for FTPS (File Transfer Protocol over SSL (FTPS))
	AWS Transfer for SFTP (Secure File Transfer Protocol (SFTP))
Managed infrastructure, Scalable, Reliable, Highly Available (multi-AZ)
Pay per provisioned endpoint per hour + data transfers in GB
Store and manage users credentials within the service
Integrate with existing authentication systems (Microsoft Active Directory, LDAP, Okta, Amazon Cognito, custom)
Usage: sharing files, public datasets, CRM, ERP, ..	

AWS DataSync - Overview
----------------------------
AWS DataSync - NFS/SMB to AWS (S3, EFS, FSx...)
Move large amount of data to and from
	On-premises/other cloud to AWS (NFS. SMB, HDFS, S3 API...) - needs agent
	AWS to AWS (different storage services) - no agent needed
Can synchronize to:
	Amazon S3 (any storage classes - including Glacier)
	Amazon EFS
	Amazon FSx (Windows, Lusture, NetApp, OpenZFS...)
Replication tasks can be scheduled hourly, daily, weekly
File permissions and metadata are preserved (NFS POSIX, SMB...)
One agent task can use 10 Gbps, can setup a bandwidth limit

Storage Comparision
---------------------
S3: Object Storage
S3 Glacier: Object Archival
EBS volumes: Network storage for one EC2 instance at a time
Instance Storage: Physical storage for your EC2 instance (high IOPS)
EFS: Network File System for Linux instances, POSIX filesystem
FSx for Windows: Network File System for Windows servers
FSx for Lusture: High Performance Computing Linux file system
FSx for NetApp ONTAP: High OS Compatibility
FSx for OpenZFS: Managed ZFS file system
Storage Gateway: S3 and FSx File Gateway, Volume Gateway (cache & stored), Tape Gateway
Transfer Family: FTP, FTPS, SFTP inerface on top of Amazon S3 or Amazon EFS
DataSync: Schedule data sync from on-premises to AWS, or AWS to AWS
Snowcone / Snowball / Snowmobile: to move large amount of data to the cloud, physically
Database: for specific workloads, usually with indexing and querying
