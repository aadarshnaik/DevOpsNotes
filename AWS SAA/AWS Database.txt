Amazon RDS Overview
--------------------
RDS Stands for Relational Database Service
It's a managed DB service for DB use SQL as a query language
It allows you to create databases in the cloud that are managed by AWS
    Postgres
    MySQL
    MariaDB
    Oracle
    Microsoft SQL Server
    Aurora (AWS Proprietary database)

Advantage over using RDS versus deploying DB on EC2
    RDS is a managed service:
        Automated provisioning, OS patching
        Continuous backups and restore to specific timestamp (Point in Time Restore)!
        Monitoring dashboards
        Read replicas for improved read performance
        Multi AZ setup for DR (Disaster Recovery)
        Maintenance windows for upgrades
        Scaling capability (vertical and horizontal)
        Storage backed by EBS (gp2 or io1)
    Can't SSH into your instances

RDS - Storage Auto Scaling
    Helps you increase storage on your RDS DB instance dynamically
    When RDS detects you are running out of free database storage, it scales automatically
    Avoid manually scaling your database storage
    You have to set Maximum Storage Threshold (maximum limit for DB storage)
    Automatically modify storage if:
        Free storage is less than 10% of allocated storage
        Low-storage lasts at least 5 minutes
        6 hours have passed since last modification
    Useful for applications with unpredictable workloads
    Supports all RDS database engines (MariaDB, MYSQL, PostgreSQL, SQL Server, Oracle)


RDS Read Replicas for read scalability
    If we want more reads and write in our database and our only db can't scales enough, we need Read Replicas
        Up to 5 Read Replicas
        Within AZ, Cross AZ or Cross Region
        Replication is ASYNC, so reads are eventually consistent
        Replicas can be promoted to their own DB
        Application must update the connection string to leverage read replicas
    Use Cases:
        You have a production database that is taking on normal load
        You want to run a reporting application to run some analytics
        You create a Read Replica to run the new workload there
        The production application is unaffected
        Read replicas are used for SELECT (=read) only kind of statements (not INSERT, UPDATE, DELETE)

        RDS Read Replicas - Network Cost
            In AWS there's a network cost when data goes from one AZ to another
            For RDS Read Replicas within the same region, you don't pay that fee
        
    RDS Multi AZ (Disaster Recovery)
        SYNC Replication
        One DNS name - automatic app failover to standby
        Increase availability
        Failover in case of loss of AZ, loss of network, instance or storage failure
        No manual intervention in apps
        Not using for scaling 
        The Read Replicas can be setup as Multi AZ for Disaster Recovery (DR)
    
    RDS - From Single-AZ to Multi-AZ
        Zero downtime operation (no need to stop the DB)
        Just click on "modify" for the database
        The following happens internally:
            A snapshot is taken
            A new DB is restored from the snapshot in a new AZ
            Synchronization is established between the two databases
    
    Hands-On:
        Databses > Create Database > Select engine > credentials > Choose Inatance Configurations >
        choose storage > enable Auto scaling if needed 
    
    RDS Custom
        Managed Oracle and Microsoft SQL Server Database with OS and database customization
        RDS: Automates setup, operation, and scaling of database in AWS
        Custom: access to the underlying database and OS so you can 
            Configure settings
            Install patches
            Enable native features
            Access the underlying EC2 Instance using SSH or SSM Session Manager
        De-activate Automation Mode to perform your customization, better to take a DB snapshot before
        RDS vs. RDS Custom
            RDS: entire database and the OS to be managed by AWS
            RDS Custom: full admin access to the underlying OS and the database



Amazon Aurora
----------------
Aurora is a proprietary technology from AWS (not open sourced)
Postgres and MySQL are both supported as Aurora DB (that means your drivers will work as if Postgres or MySQL database)
Aurora is "AWS cloud optimized" and claims 5x performance improvement over MySQL on RDS, over 3x the performance of Postgres on RDS
Aurora storage automatically grows in increments of 10GB, up to 128 TB.
Aurora can have 15 replicas while MySQL has 5, and replication process is faster (sub 10ms replica lag)
Failover in Aurora is instantaneous. It's HA native.
Aurora costs more than RDS (20% more) - but is more efficient

Aurora High Availability and Read Scaling
    6 copies of your data across 3 AZ:
        4 copiees out of 6 needed for writes
        3 copiees out of 6 need for reads
        Self healing with peer-to-peer replication
        Storage is striped across 100s of volumes
    One Aurora Instance that writes (master)
    Automated failover for master in less than 30 seconds
    Master + up to 15 Aurora Read Replicas serve reads
    Support for Cross Region replication

Aurora DB Cluster
    Master is the only think that will write to the storage
    Client talks to the "Writer-End-Point" that is always pointing to master
    There is Read-replicas and we can enable auto-Scaling on it.
    There is "Reader-End-Point" that helps with connection load balancing and it connects automatically to all the read-replicas

    Features of Aurora  
        Automatic failover
        Backup and Recovery
        Isolation and security
        Industry compliance
        Push-button scaling
        Automated Patching with Zero Downtime
        Advanced Monitoring
        Routine Maintenance
        Backtrack: restore data at any point of time without using backups

Aurora Replicas - Auto Scaling
    If there are many Requests on Reader-Endpoint the Aurora databases will have 
    increased CPU Usage. In this case we can setup Replica Autoscaling. The Reader-Endpoint is going to be 
    extended to new Aurora Replicas created because of Autoscaling.

Aurora - Custom Endpoints
    There are Aurora databases of differnet sizes (i.e., db.r3.large and db.r5.2xlarge)
    We will define a Custom Endpoint on the db.r5.2xlarge. Basically we define a subset of Aurora Instances as a Custom Endpoint
    As these instances are powerful so they would be better to run Analytical queries on these specific replicas
    The Reader Endpoint is generally not used after defining Custom Endpoints
    We setup many custom Endpoint for many different kinds of workloads allowing us to query only a subset of aurora replicas

Aurora Serverless
    Automated database instantiation and auto-scaling based on actual Usage
    Good for infrequent, intermittent or unpredictable workloads
    No capacity planning needed
    Pay per second, can be more cost-effective

Aurora Multi-Master
    In case we want immediate failover for writer node (High Availability) -
    Every node does R/W 

Global Aurora
    Aurora Cross Region Read Replicas:
        Useful for disaster Recovery   
        Simple to put in place
    Aurora Global Database (recommended):
        1 Primary Region (read/write)
        Up to 5 secondary (read-only) regions, replication lag is less than 1 second
        Up to 16 Read Replicas per secondary region
        Helps in decreasing latency
        Promoting another region (for disaster recovery) has an RTO of < 1 minute
        **Typically cross-region replication takes less than 1 second**

Aurora Machine Learning
    Enables you to add ML-based predictions to your applications via SQL
    Simple, optimized and secure integration between Aurora and AWS ML services
    Supported services  
        Amazon SageMaker (usw with ML model)
        Amazon Comprehend (for sentiment analysis)
    You don't need to have ML experience
    Use cases: fraud detection, ads targeting, sentiment analysis, product recommendations


RDS backups 
    Automated backups:
        Daily full backup of the database (during the backup window)
        Transaction Logs are backed-up by RDS every 5 minutes
        => ability to restore to any point in time (from oldest backup to 5 minutes ago)
        1 to 35 days of retention, set 0 to disable automated backups
    Manual DB Snapshots
        Manually triggered by the user
        Retention of backup for as long as you want
    
    Trick: In a stopped RDS database, you will still pay for storage. If you plan on stopping it 
    for a long time, you should snapshot & restore instead

Aurora Backups
    Automated Backups   
        1 to 35 days (cannot be disabled)
        point-in-time recovery in the timeframe
    Manual DB Snapshots
        Manually triggered by the user
        Retention of backup for as long as you want
    
RDS & Aurora Restore options
    Restoring a RDS/Aurora backup or a snapshot created a new database
    Restoring MySQL RDS database from S3
        Create a backup of your on-premises database
        Store it on Amazon S3 (object storage)
        Restore the backup file onto a new RDS instance running MySQL
    Restoring MySQL Aurora cluster from S3
        Create a backup on your on-premises database using Percona XtraBackup
        Store the backup file on Amazon S3
        Restore the backup file onto a new Aurora cluster running MySQL


Aurora Database Cloning
    Create a new Aurora DB Cluster from an existing one
    Faster than snapshot & restore
    The new DB cluster uses the same cluster volume and data as the original but will change when data updates are made
    Very fast & cost-effective
    Useful to creata a "staging" database from a "production" database without impacting the production database


RDS & Aurora security
-----------------------

At-rest encryption
    Database master & replicas encryption using AWS KMS - must be defined as launch time
    If the master is not encrypted, the read replicas cannot be encrypted
    To encrypt an un-encrypted database, go through DB snapshot and restore as encrypted

In-flight encryption: TLS-ready by default, use the AWS TLS root certificates client-side

IAM Authentication: IAM roles to connect to your database (instead of username/pw)

Security Groups: Control Network Access to your RDS/Aurora DB

No SSH available except on RDS Custom

Audit Logs can be enabled and sent to CloudWatch Logs for longer retention


Amazon RDS Proxy
------------------

- Fully managed database proxy for RDS
- Allows apps to pool and share DB Connections established with the database
- Improving database efficiency by reducing the stress on database resources (eg CPU, RAM) and 
  minimize open connections (and timeouts)
- Serverless, autoscaling, high available (multi-AZ)
- Reduced RDS & Aurora failover time by up 66%
- Supports RDS (MySQL, PostgreSQL, MariaDB) and Aurora (MySQL, PostgreSQL)
- No code changes required for most apps
- Enforce IAM Authentication for DB, and securely store credentials in AWS Secrets Manager
- RDS Proxy is never publically accessible (must be accessed from VPC)

Use Case:
    When we use Lambda Functions if they access the DB they will connect and disconnect very fast 
    resulting in open connections and timeouts. So we use RDS Proxy to pool the connections into less
    connection to RDS Instance



Amazon ElastiCache 
--------------------

The same way RDS is to get managed Relational Databases ElastiCache is to get managed Redis or Memcached
Cache are in-memory databases with really high performance, low latency
Helps reduce load off of databases for read intensive workloads
Helps make your application stateless
AWS takes care of OS maintenance / patching, optimizations, setup, configuration, monitoring, failure recovery and backups.
Using ElastiCache involves heavy application code changes

ElastiCache Solution Architecture - DB Cache
    Application queries ElastiCache, if not available, get from RDS and store in ElastiCache
    Helps relieve load in RDS
    Cache must have an invalidation strategy to make sure the most current data is used there

ElastiCache Solution Architecture - User Session Store
    User logs into any of the application
    The application writes the session data into ElastiCache
    The user hits another instance of our application 
    The instance retrieves the data and the user is already logged in

ElastiCache -  Redis vs Memcached
    Redis
        Multi AZ with Auto-Failover
        Read Replicas to scale reads and have high availability
        Data Durability using AOF persistence
        Backup and restore features
    Memcached
        Multi-node for partitioning of data (sharding)
        No high availability (reploication)
        Non persistent
        No backup and restore
        Multi-threaded Architecture

ElastiCache - Cache Security
    All cache in ElastiCache:
        Do not support IAM Authentication
        IAM policies on ElastiCache are only used for AWS API-level security
    Redis AUTH
        You can set a "password/token" when you create a Redis cluster
        This is an extra level of security for your cache (on top of security groups)
        Support SSL in flight encryption
    Memcached
        Supports SASL-based authentication (advanced)

Pattern for ElastiCache
    Lazy Loading: all the read data is cached, data can become stale in cache
    Write Through: Adds or update data in the cache when written to a DB (no stale data)
    Session Store: store temporary session data in the cache (using TTL features)


ElastiCache - Redis Use Case
    Gaming Leaderboards are computationally complex
    Redis Sorted sets gurantee both uniqueness and element ordering
    Each time a new element added, it's ranked in real time, then added in correct order