Scalability & High Availability
---------------------------------
Scalability means that an application/system can handle greater loads by adapting
There are two kinds of Scalability:
    Vertical Scalability
    Horizontal Scalability (=elasticity)
Scalability is linked but different to High Availability

    Vertical Scalability
        Vertical Scalability means increasing the size of instance
        For example, your application runs on a t2.micro
        Scaling that application vertically means running on a t2.large
        Vertical scalability is vert common for non distributed systems. such as a database
        RDS, ElastiCache are services that can scale vertically.
        There's usually a limit to how much you can vertically scale (hardware limit)
    
    Horizontal Scalability
        Horizontal Scalability means increasing the number of instances/systems for your application
        Horizontal scaling implies distributed systems
        This is very common for web applications/modern applications
        It's easy to horizontally scale thanks to cloud offerings such as Amazon EC2


High Availability
    High Availability usually goes hand in hand with horizontal scaling
    High availability means running your application/system in at least 2 data centers (== Availability Zones)
    The goal of high availability is to servive a data center loss
    The high availability can be passive (for RDS Multi AZ for example)
    The high availability can be active (for horizontal scaling)

Load Balancing
-----------------
Load Balances are servers that forward traffic to multiple servers (e.g./ EC2 instances) downstream
Load Balancers spread across multiple downstream instances

Why use a load balancer ?
    Spread laod across multiple downstream instances
    Expose a single point of access (DNS) to your application
    Seamlessly handle failures of downstream instances
    Do regular health checks to your instances
    Provide SSL termination (HTTPS) for your websites
    Enforce stickiness with cookies
    High availability across Zones
    Separate public trafffic from private traffic

Why use an Elastic Load Balancer?
    AWS gurantees that it will be working
    AWS takes care of upgrades, maintenance, high availability
    AWS provides only a few configuration knobs

It costs less to setup your own load balancer but it will be a lot more effort on your end

It is integrated with many AWS offerings/services
    EC2, EC2 Auto Scaling Groups, Amazon ECS
    AWS Certificate Manager (ACM), CloudWatch
    Route 53, AWS WAF, AWS Global Accelerator

Health Checks
    Health Checks are crucial for Load Balancers
    They enable the load balancer to know if instances it forwards traffic to are available to reply to requests
    The health check is done on a port and a route (/health is common)
    If the response is not 200 (OK), then the instance is unhealthy

Types of Load Balancers
-------------------------
- Classic Load Balancer (v1 - old generation) - 2009 - CLB
    HTTP, HTTPS, TCP, SSL (SecureTCP)
- Application Load Balancer (v2 - new generation) - 2016 - ALB
    HTTP, HTTPS, WebSocket
- Network Load Balancer (v2 - new generation) - 2017 - NLB
    TCP, TLS (secure TCP), UDP
- Gateway Load Balancer - 2020 - GWLB
    Operated at layer 3 (Network layer) - IP Protocol

Overall, it is recommended to use the newer generation load balancers as they provide more features
Some load balancers can be setup as internal(private) or external(public) ELBs

    Application Load Balancer (v2)
    --------------------------------
        Application load balancers is Layer 7 (HTTP)
        Load balancing to multiple HTTP applications across machines (target groups)
        Support for HTTP/2 and WebSocket
        Support redirects (from HTTP to HTTPS for example)
        Routing tables to different target groups:
            Routing based in path in URL (example.com/users)
            Routing based on hostname in URL (one.example.com & other.example.com)
            Routing based on Query String, Headers (example.com/users?id=123&order=false)
        ALB are a great fit for micro services & container-based application
        Has a port mapping feature to redirect to a dynamic port in ECS
        In comparision, we'd need multiple Classic Load Balancer per application

        Target Groups
            EC2 instances (can be managed by an Auto Scaling Group) - HTTP
            ECS tasks (managed by ECS itself) - HTTP
            Lambda functions - HTTP request is translated into a JSON event
            IP Addresses - must be private IPs
            ALB can route to multiple target groups
            Health checks are at the target group level
        
        Good To Know
            Fixed hostname (XXX.region.elb.amazonaws.com)
            The application servers don't see the IP of the client directly
                The true IP of the client is inserted in the header X-Forwarded-For
                We can also get Port (X-Forwarded-Port) and proto (X-Forwarded-Proto)
    
    
    Hands-On:
        Launch 2 instances with a same security-group for both (launch-wizard-1)
        Load Balancer > Application Load Balancer > Enter details > Network mapping -all 
        > Create a new SG and allow HTTP traffic > Choose new SG > Create Target Group and add the instances > 
        chooose new TG in Listners and routing section > Create Load Balancer

        From launch-wizard-1 sg we remove inbound rules with incomming HTTP requests from 0.0.0.0/0
        and add inbound rule accepting tarffic from load-balancer SG only.

        Load Balancer > Listners > ClickOn ALB > Rules > Manage Rules > We can add custom rules


    Network Load Balancer(v2)
    --------------------------
        Network Load Balancers (Layer 4) allow to:
            Forward TCP and UDP traffic to your instances
            Handle millions of request per seconds
            Less latency ~ 100ms (vs 400ms for ALB )
        NLB has one static IP per AZ, and supports assigning Elastic IP
        (helpful for whitelisting specific IP)
        NLB are used for extreme performance, TCP or UDP traffic
        Not included in the AWS free tier
        NLB Target Groups:
            EC2 instances
            IP Addresses - must be private IPs
            Application Load Balancer
            Health Checks support the TCP, HTTP and HTTPS Protocols
        
    Hands-On:
        Create a Load Balancer > Network Load Balancer > Network Mapping select all > 
        Create a target group and add all instances > chooose new TG in Listners and routing section >
        In the Security Group of the instances we need to add inbound rule for Http access from 0.0.0.0/0
        
        For NLB we don't define Security group for it. The Security group of EC2 defines access.


    Gateway Load Balancer:
    -----------------------
        Deploy, scale, and manage a fleet of 3rd party network virtual appliances in AWS
        Example: Firewalls, Intrusion Detection and Prevention Systems, Deep Packet Inspection Systems, 
        payload manipulation, ...       

        Operated at Layer 3 (Network Layer) - IP Packets
        Combines the following functions:
            Transparent Network Gateway - single entry/exit for all traffic
            Load Balancer - distributes traffic to your virtual appliances
        Uses the GENEVE protocol on port 6081

        Gateway Load Balancer target Groups can be EC2 Instances, IP Addresses - must be private IPs

Sticky Sessions (Session Affinity)
------------------------------------
It is possible to implement stickiness so that the same client is always redirected to the same instance behind the load balancer
This works for Classic Load Balancers & Application Load Balanvers
The "cookie" is used for stickiness has an expiration date we control
Use case: Make seure the user doesn't loose his session data
Enabling stickiness may bring imbalance to the load over the backend EC2 instances

    Sticky Sessions - Cookie Names  
        Application-based cookies
            Custom cookies
                Generated by the target
                Can include any custom attributes required by the application
                Cookie name must be specified individually for each target group
                Don't use AWSALB, AWSALBAPP, or AWSALBTG (reserved for use by the ELB)
            Application cookie
                Generated by the load balancer
                Cookie name is AWSALBAPP
        Duration-based Cookies
            Cookie generated by the load balancer
            Cookie name is AWSALB for ALB, AWSELB for CLB
        
        To enable cookie:
            Target Group > Actions > Edit attributes > Stickiness > Select type of Cookie > Save Changes

Cross-Zone Load Balancing
---------------------------
With Cross Zone Load Balancing:
    each load balancer instance even if in differnet AZ distributes traffic 
    evenly across all registered instances in all AZ.
Without Cross Zone Load Balancing:
    Requests are distributed to the instances of the node of the Elastic Load Balancer. Th ALB is
    going to send the traffic to the instances in its own AZ


SSL/TLS - Basics
------------------
  - An SSL Certificate allows traffic between your clients and your load balancer to be 
    encrypted in transit (in-flight encryption)
  - SSL refers to Secure Sockets Layer, used to encrypt connections
  - TLS refers to Transport Layer Security, which is a newer version
  - Nowadays, TLS Certificates are mainly used, but people still refer as SSL
  - Public SSL certificates are issued by Certificate Authorities (CA)
  - Comodo, Symantec, GoDaddy, GlobalSign, Digicert, Letsencrypt, etc...
  - SSL certificates have an expiration date and must be renewed

    Load Balancer - SSL Certificates
        The load balancer uses an X.509 certificate (SSL/TLS server certificate)
        You can manage certificates using ACM (AWS Certificate Manager)
        You can create upload your own certificates alternatively
        HTTPS listener:
            You must specify a default certificate
            You can add an optional list of certs to support multiple domains
            Clients can use SNI (Server Name Indication) to specify the hostname they reach
            Ability to specify a security policy to support older versions of SSL/TLS (legacy clients)
        
        SSL - Server Name Indication (SNI)
            SNI solves the problem of loading multiple SSL certificates onto one web server (to serve multiple websites)
            It's a "newer" protocol, and requires the client to indicate the hostname of the target server in the initial SSL handshake
            The server will then find the correct certificate, or return the default one
            Note:
                Only works for ALB & NLB (newer generation), CloudFront
                Does not work for CLB (older gen)
    
    Elastic Load Balancers - SSL Certificates

        Classic Load Balancer (v1)
            Support only one SSL certificate
            Must use multiple CLB for multiple hostname with multiple SSL certificates
        Application Load Balancer (v2)
            Supports multiple listeners with multiple SSL certificates
            Uses Server Name Indication (SNI) to make it work
        Network Load Balancer (v2)
            Supports multiple listeners with multiple SSL certificates
            Uses Server Name Indication (SNI) to make it work

How to enable SSL Certificates on both ALB and NLB ?

    EC2 > Load balancers > Select ALB > Add Listener > Add port > Add TG >  Select security policy > 

Connection Draining
--------------------
Feature naming
    Connection Draining - for CLB
    Deregistration Delay - for ALB & NLB

Time to complete "in-flight requests" while the instance is de-registering or unhealthy
Stop sending new requests to the EC2 instance which is de-registering
Between 1 to 3600 seconds (default: 300 seconds)
Can be disabled (set value to 0)
Set to a low value if your requests are short



Auto Scaling Groups (ASG)
--------------------------
In real-life, the ;load on your websites are application can Change
In the cloud, you can create and get rid of servers very quickly
The goal of an Auto Scaling Group (ASG) is to:
    Scale out (add EC2 instances) to match an increased load
    Scale in (remove EC2 instances) to match a decreased load
    Ensure we have a minimum and a maximum number of EC2 instances running
    Automatically register new instances to a load balancer
    Re-create an EC2 instance in case a previous one is terminated (ex: if unhealthy)
ASG are free (you only pay for the underlying EC2 instances)

A Launch Template (older "Launch Configurations" are deprecated)
    AMI + Instance Type
    EC2 User Data 
    EBS Volumes
    Security Groups
    SSH Key Pair
    IAM Roles for your EC2 Instances
    Network + Subnets Information
    Load Balancer Information
Min Size / Max Size / Initial Capacity
Scaling Policies

Auto Scaling - CloudWatch Alarms & Scaling
    It is possible to scale an ASG based on CloudWatch Alarms
    An alarm monitors a metric (such as Average CPU, or a custom metric)
    Metrics such as Average CPU are computed for the overall ASG instances
    Based on the alarm:
        We can scale-out policies (increase the number of instances)
        We can scale-in policies (decrease the number of instances)

Auto Scaling Groups - Dynamic Scaling Policies
    Target Tracking Scaling
        Most simple and easy to set-up
        Example: I want the average ASG CPU to stay at around 40%
    Simple / Step Scaling
        When a CloudWatch alarm is triggered (example CPU > 70%), then add 2 units
        When a CloudWatch alarm is triggred (example CPU < 30%), then remove 1
    Scheduled Actions
        Anticipate a scaling based on known usage patterns
        Example: increase the min capacity to 10 to 5 pm on Fridays 
    Prdeicitive Scaling
        Continuously forecast and schedule scaling ahed
    
    Good metrics ro scale on:
        CPUUtilization: Average CPU utilization across your instances
        RequestCountPerTarget: To make sure the number of requests per EC2 instances is stable
        Average Network In/Out (if you're application is network bound)
        Any custom metric (that you push using CloudWatch)
    
    Auto Scaling Groups - Scaling Cooldowns
        After a scaling activity happens, you are in the cooldown period (default 300 seconds)
        During the cooldown period, the ASG will not launch or terminate additional instances (to allow for metrics to stabilize)
        Advice : Use a ready-to-use AMI to reduce configuration time in order to be serving requests fasters and reduce the cooldown period